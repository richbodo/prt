# Feature: System Prompt Optimization for LLM Integration

## Summary

Optimize the PRT system prompt for LLM interactions by reducing size from ~19,800 characters to ~8,000 characters (60% reduction) while maintaining or improving effectiveness. The current prompt contains significant redundancy and over-detailed reference information that can be restructured for better performance.  The system prompt is not a static file, but rather a prompt generated by code that reads in tool descriptions and other data from the app.

## Problem Statement

The current system prompt generated by `python -m prt_src prt-debug-config` has several issues:

1. **Excessive Length**: 19,803 characters causes slower LLM processing and higher token costs
2. **Redundant Information**: Security rules, SQL patterns, and usage instructions repeated 3-4 times throughout
3. **Over-Detailed Schema**: Full database schema dump takes ~25% of prompt space for reference information
4. **Poor Information Architecture**: Critical operational guidance mixed with reference material
5. **Maintenance Burden**: Adding new features exponentially increases prompt size

### Current Redundancy Examples
- SQL security rules mentioned in 4 different sections
- Performance optimization patterns scattered throughout
- Tool descriptions listed both briefly and in detail
- 20+ SQL examples when 5 template patterns would suffice

## Proposed Solution

Restructure the system prompt using a hierarchical information architecture:

**CORE (Must Know)** → **PATTERNS (How To)** → **REFERENCE (Lookup)**

### Target Structure (~8,000 characters)

#### Section 1: Core Identity & Role (500 chars)
```
You are the AI assistant for PRT (Personal Relationship Toolkit), a privacy-first local contact manager.

Your role: Natural language interface for searching, managing, and understanding contact relationships in a TUI environment. Keep responses concise for terminal display. All data is local-only.
```

#### Section 2: Critical Security (800 chars)
```
MANDATORY SECURITY RULES (code-enforced, cannot bypass):
• ALL SQL queries require confirm=true - always ask user first
• Write operations auto-create backups before execution
• SQL injection protection blocks multiple statements/comments
• Never bypass safety features - they're hard-coded protections

Format: "I can run: [query]. Should I execute it?"
```

#### Section 3: Tools & Usage Patterns (1,500 chars)
```
KEY TOOLS (26 total):
Read: search_contacts, list_all_*, get_contact_details, search_tags/notes
Write: add/remove_tag, create/delete_*, add/remove_note (auto-backup)
Advanced: execute_sql (needs confirm), generate_directory (user request only)

WORKFLOW:
1. Search first - never invent data
2. SQL only for complex queries other tools can't handle
3. Directory generation: offer for 10+ results, never auto-create
4. Write ops: inform user of backup ID created
```

#### Section 4: Database Essentials (1,200 chars)
```
CORE TABLES:
• contacts: id, name, email, phone, profile_image (binary), first/last_name
• tags/notes: categorical labels and free-form text
• contact_metadata: links contacts to tags/notes
• contact_relationships: contact-to-contact links with types

PERFORMANCE RULES:
• Always LIMIT large queries (50-100 max)
• Exclude profile_image from SELECT unless needed (50-500KB each)
• Use COUNT(*) before large result sets
• Indexed fields: name, email, created_at
```

#### Section 5: Common Patterns (1,000 chars)
```
FREQUENT REQUESTS:
• "Find X contacts" → search_contacts or list_all_contacts
• "Tag X as Y" → add_tag_to_contact (backup auto-created)
• "Show family" → get_contacts_by_tag
• "Contacts with photos" → SQL with profile_image IS NOT NULL LIMIT 50
• "Create directory" → generate_directory (ask user first)

SQL TEMPLATES:
• All contacts: SELECT id, name, email FROM contacts LIMIT 50
• With images: SELECT id, name FROM contacts WHERE profile_image IS NOT NULL LIMIT 50
• By tag: Use get_contacts_by_tag tool instead of SQL
```

## Implementation Plan

### Phase 1: Quick Wins (40% reduction)
1. **Consolidate Security Sections**
   - Remove 3 duplicate security rule sections
   - Keep single authoritative version in Section 2

2. **Simplify SQL Examples**
   - Replace 20+ specific queries with 5 template patterns
   - Focus on most common use cases (90% coverage)

3. **Summarize Database Schema**
   - Keep essential table/column info only
   - Move full schema details to external reference

### Phase 2: Structural Optimization (20% additional reduction)
1. **Hierarchical Information Architecture**
   - Core operational guidance first
   - Reference material last
   - Clear separation of concerns

2. **Tool Grouping by Function**
   - Group by Read/Write/Advanced instead of alphabetical
   - Emphasize workflow patterns over individual tools

3. **Context-Aware Content**
   - Include only relevant information for common tasks
   - Reduce cognitive load on LLM processing

### Phase 3: Advanced Optimization (Future)
1. **Dynamic Schema Injection**
   - Include only relevant table details based on query context
   - Reduce static schema information

2. **External Reference System**
   - Link to schema/tool documentation
   - Keep prompt focused on operational guidance

3. **A/B Testing Framework**
   - Compare response quality across prompt variations
   - Measure performance improvements

## Files to Modify

### Core Changes
- `prt_src/llm_prompts/database_chat_system_prompt.txt` - Main system prompt file
- `prt_src/debug_info.py` - System prompt generation logic
- Related LLM integration files that build the system prompt

### Supporting Changes
- `docs/LLM_Integration/` - Update documentation to reflect optimized approach
- Test files that validate system prompt content

## Acceptance Criteria

### Functional Requirements
- [ ] System prompt reduced to ~8,000 characters (60% reduction from current 19,803)
- [ ] All critical security rules preserved and consolidated
- [ ] Essential workflow patterns clearly defined
- [ ] Database schema information streamlined but complete
- [ ] Tool usage guidance consolidated and clear

### Quality Requirements
- [ ] LLM response quality maintained or improved
- [ ] No loss of functionality in chat interactions
- [ ] Reduced token usage for each chat session
- [ ] Faster LLM processing due to shorter context
- [ ] Easier maintenance and updates

### Testing Requirements
- [ ] Existing LLM integration tests continue to pass
- [ ] Chat functionality works with optimized prompt
- [ ] Security features remain fully functional
- [ ] Performance improvement measurable (response time/token usage)

## Success Metrics

### Performance Metrics
- **Token Reduction**: From ~19,800 to ~8,000 characters (60% reduction)
- **Processing Speed**: Faster LLM response times due to shorter context
- **Cost Reduction**: Significant decrease in token usage per interaction

### Quality Metrics
- **Response Accuracy**: Maintain or improve correct tool usage
- **Security Compliance**: 100% preservation of security rules
- **User Experience**: Maintain chat functionality quality

### Maintenance Metrics
- **Update Complexity**: Easier to add new features without exponential growth
- **Documentation Clarity**: Clear separation of core vs. reference information
- **Code Maintainability**: Single source of truth for security and patterns

## Risks and Mitigation

### Risk: Response Quality Degradation
**Mitigation**:
- Comprehensive testing with existing chat scenarios
- A/B testing framework to compare prompt variations
- Gradual rollout with fallback to original prompt

### Risk: Missing Critical Information
**Mitigation**:
- Systematic review of all removed content
- Preserve all security-critical sections
- External reference documentation for removed details

### Risk: Maintenance Complexity
**Mitigation**:
- Clear documentation of new prompt structure
- Automated testing of prompt generation
- Version control for prompt changes

## Related Issues

- Performance optimization for large contact databases
- LLM integration improvements
- Token usage cost optimization
- Chat response time improvements

## Notes

This optimization maintains all current functionality while significantly improving performance and maintainability. The key insight is separating "must know immediately" information from "can reference when needed" information.

The hierarchical structure ensures LLMs focus on essential operational guidance first, with reference material clearly separated and condensed.